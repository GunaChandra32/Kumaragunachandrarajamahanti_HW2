{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MFOAi7RY1gmy"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Variables\n",
        "splitted_data = []\n",
        "vocab = []\n",
        "corpous_data = {}"
      ],
      "metadata": {
        "id": "abRt5CJx2ARL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It converts each word to a new encrypted word using provided corpus data\n",
        "def bpe_encrypt(actual_tokens, corpus_data):\n",
        "    if len(actual_tokens) == 1:\n",
        "        return actual_tokens\n",
        "    token = list(actual_tokens)\n",
        "    while True:\n",
        "        bpe_pairs = {}\n",
        "        pairs = get_possible_pairs(token)\n",
        "        for pair in pairs:\n",
        "            if pair in corpus_data:\n",
        "                bpe_pairs[pair] = corpus_data[pair]\n",
        "        if not bpe_pairs:\n",
        "            break\n",
        "        pair_to_merge = max(bpe_pairs, key=bpe_pairs.get)\n",
        "        token = generate_new_token(token, pair_to_merge)\n",
        "    return token"
      ],
      "metadata": {
        "id": "_A4Mywf42F3K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It returns all matched pairs of a given word\n",
        "def get_possible_pairs(word):\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "    return pairs"
      ],
      "metadata": {
        "id": "n65TUWhg2IMx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It replaces the matched characters with the encrypted pair values\n",
        "def generate_new_token(input_word, character_pair):\n",
        "    first_char, second_char = character_pair\n",
        "    output_word = []\n",
        "    index = 0\n",
        "    while index < len(input_word):\n",
        "        try:\n",
        "            char_index = input_word.index(first_char, index)\n",
        "            output_word.extend(input_word[index:char_index])\n",
        "            index = char_index\n",
        "        except ValueError:\n",
        "            output_word.extend(input_word[index:])\n",
        "            break\n",
        "        if index < len(input_word) - 1 and input_word[index + 1] == second_char:\n",
        "            output_word.append(first_char + second_char)\n",
        "            index += 2\n",
        "        else:\n",
        "            output_word.append(first_char)\n",
        "            index += 1\n",
        "    return output_word"
      ],
      "metadata": {
        "id": "eq7whd-42L9c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function used to Split Words\n",
        "def get_splitted_words(words):\n",
        "    for word in words:\n",
        "        splitted_data.append(list(word.lower()))\n",
        "    return splitted_data\n",
        "\n",
        "# Function to get Initial Vocabs\n",
        "def get_vocab(splitted_data):\n",
        "    for word in splitted_data:\n",
        "        for character in word:\n",
        "            if character not in vocab:\n",
        "                vocab.append(character)\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "7ptXF8jf2O27"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BPE Algorithm - Training Corpus Data\n",
        "def bpe(iteration):\n",
        "    print('-'*5, f\"Iteration - {iteration+1}\", '-'*5)\n",
        "    global splitted_data, vocab\n",
        "    global corpous_data\n",
        "    pairs = defaultdict(int)\n",
        "    for word in splitted_data:\n",
        "        for i in range(len(word) - 1):\n",
        "            pairs[word[i], word[i + 1]] += 1\n",
        "    if pairs:\n",
        "        # Get pair which has maximum frequency\n",
        "        best = max(pairs, key=pairs.get)\n",
        "        print(\"maxium frequency\", best, pairs[best])\n",
        "        corpous_data[best] = pairs[best]\n",
        "        # Merge Pair and Add to Vocabs\n",
        "        vocabs.append(''.join(best))\n",
        "        temp_splitted_data = []\n",
        "        # Update Merged Pair in sentence splitted_data\n",
        "        for word in splitted_data:\n",
        "            if len(word) > 1:\n",
        "                skipNext = False\n",
        "                temp = []\n",
        "                for i in range(len(word) - 1):\n",
        "                    if skipNext:\n",
        "                        skipNext = False\n",
        "                        continue\n",
        "                    if [word[i], word[i + 1]] == [best[0], best[1]]:\n",
        "                        temp.append(''.join(best))\n",
        "                        skipNext = True\n",
        "                    else:\n",
        "                        temp.append(word[i])\n",
        "                if [word[-2], word[-1]] != [best[0], best[1]]:\n",
        "                    temp.append(word[-1])\n",
        "                # print(word, temp)\n",
        "                temp_splitted_data.append(temp)\n",
        "        if temp_splitted_data != []:\n",
        "            splitted_data = temp_splitted_data.copy()\n",
        "        # print(\"splitted_data\",splitted_data)\n",
        "        print(\"Vocabulary\", vocabs)\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "yePlCyci2Va8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Baker Betty Lou bought some butter. But, it made her batter bitter. So, Baker Betty Lou bought some better butter to make her bitter batter better.\"\n",
        "iterations = 10\n",
        "tokens = re.findall(r'\\b\\w+\\b', input_text)\n",
        "splitted_data = get_splitted_words(tokens)\n",
        "vocabs = get_vocab(splitted_data)\n",
        "print(\"*\"*5, \"Training Corpus Data\", \"*\"*5)\n",
        "print('-'*5, f\"Initial Vocabulary\", '-'*5)\n",
        "print(\"Vocabulary\", vocabs)\n",
        "for iteration in range(iterations):\n",
        "    if bpe(iteration) == False:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsv1-rXK2Wap",
        "outputId": "f829f9d9-dbb3-442e-beb7-06686be9a4ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Training Corpus Data *****\n",
            "----- Initial Vocabulary -----\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd']\n",
            "----- Iteration - 1 -----\n",
            "maxium frequency ('e', 'r') 12\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er']\n",
            "----- Iteration - 2 -----\n",
            "maxium frequency ('t', 't') 10\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt']\n",
            "----- Iteration - 3 -----\n",
            "maxium frequency ('tt', 'er') 8\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt', 'tter']\n",
            "----- Iteration - 4 -----\n",
            "maxium frequency ('b', 'a') 4\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt', 'tter', 'ba']\n",
            "----- Iteration - 5 -----\n",
            "maxium frequency ('b', 'e') 4\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt', 'tter', 'ba', 'be']\n",
            "----- Iteration - 6 -----\n",
            "maxium frequency ('o', 'u') 4\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt', 'tter', 'ba', 'be', 'ou']\n",
            "----- Iteration - 7 -----\n",
            "maxium frequency ('s', 'o') 3\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt', 'tter', 'ba', 'be', 'ou', 'so']\n",
            "----- Iteration - 8 -----\n",
            "maxium frequency ('b', 'u') 3\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt', 'tter', 'ba', 'be', 'ou', 'so', 'bu']\n",
            "----- Iteration - 9 -----\n",
            "maxium frequency ('ba', 'k') 2\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt', 'tter', 'ba', 'be', 'ou', 'so', 'bu', 'bak']\n",
            "----- Iteration - 10 -----\n",
            "maxium frequency ('bak', 'er') 2\n",
            "Vocabulary ['b', 'a', 'k', 'e', 'r', 't', 'y', 'l', 'o', 'u', 'g', 'h', 's', 'm', 'i', 'd', 'er', 'tt', 'tter', 'ba', 'be', 'ou', 'so', 'bu', 'bak', 'baker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"*\"*5, \"Choosen Corpus Data\", \"*\"*5)\n",
        "print(*corpous_data.items(),sep=\"\\n\")\n",
        "print(\"*\"*5, \"Sample Test\", \"*\"*5)\n",
        "testing_word = 'bitter'\n",
        "result = bpe_encrypt(testing_word, corpous_data)\n",
        "print(f\"Input Text: {testing_word}\")\n",
        "print(f\"BPE_Tokens: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehW0Opeu2bGq",
        "outputId": "af1a44f1-5690-4d54-b5b4-14280fbc5139"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Choosen Corpus Data *****\n",
            "(('e', 'r'), 12)\n",
            "(('t', 't'), 10)\n",
            "(('tt', 'er'), 8)\n",
            "(('b', 'a'), 4)\n",
            "(('b', 'e'), 4)\n",
            "(('o', 'u'), 4)\n",
            "(('s', 'o'), 3)\n",
            "(('b', 'u'), 3)\n",
            "(('ba', 'k'), 2)\n",
            "(('bak', 'er'), 2)\n",
            "***** Sample Test *****\n",
            "Input Text: bitter\n",
            "BPE_Tokens: ['b', 'i', 'tter']\n"
          ]
        }
      ]
    }
  ]
}